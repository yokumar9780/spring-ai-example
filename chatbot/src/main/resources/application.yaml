spring:
  application:
    name: chatbot
  ai:
    ollama:
      chat:
        options:
          model: llama3.2
      #base-url: http://localhost:11434 # url when running on local machine
      base-url: http://host.docker.internal:11434 #ollam url when running on docker

logging:
  level:
    org:
      springframework:
        ai: debug

server:
  port: 8081